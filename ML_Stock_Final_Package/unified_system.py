#!/usr/bin/env python3
"""
Unified ML Stock Prediction System
Complete integration with Yahoo Finance and Alpha Vantage
"""

import os
import sys
import json
import time
import pickle
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

os.environ['FLASK_SKIP_DOTENV'] = '1'

from flask import Flask, jsonify, request, Response
from flask_cors import CORS

import pandas as pd
import numpy as np

# ML Libraries
try:
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler
    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
    import xgboost as xgb
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False
    print("WARNING: ML libraries not fully available")

# Yahoo Finance
try:
    import yfinance as yf
    YF_AVAILABLE = True
except ImportError:
    YF_AVAILABLE = False
    print("WARNING: yfinance not available")

# Configuration
try:
    from config import ALPHA_VANTAGE_API_KEY
except:
    ALPHA_VANTAGE_API_KEY = '68ZFANK047DL0KSR'

app = Flask(__name__, static_folder='.', static_url_path='')
CORS(app)

# Global state
system_state = {
    'yahoo': 'checking',
    'alpha_vantage': 'configured',
    'ml_models': {},
    'last_predictions': {},
    'training_status': {}
}

class TechnicalIndicators:
    """Calculate 35+ technical indicators"""
    
    @staticmethod
    def calculate_all(df: pd.DataFrame) -> pd.DataFrame:
        """Calculate all technical indicators"""
        df = df.copy()
        
        # Price-based indicators
        df['SMA_5'] = df['Close'].rolling(window=5).mean()
        df['SMA_10'] = df['Close'].rolling(window=10).mean()
        df['SMA_20'] = df['Close'].rolling(window=20).mean()
        df['SMA_50'] = df['Close'].rolling(window=50).mean()
        df['EMA_12'] = df['Close'].ewm(span=12, adjust=False).mean()
        df['EMA_26'] = df['Close'].ewm(span=26, adjust=False).mean()
        
        # MACD
        df['MACD'] = df['EMA_12'] - df['EMA_26']
        df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
        df['MACD_hist'] = df['MACD'] - df['MACD_signal']
        
        # RSI
        delta = df['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['RSI'] = 100 - (100 / (1 + rs))
        
        # Bollinger Bands
        df['BB_middle'] = df['Close'].rolling(window=20).mean()
        bb_std = df['Close'].rolling(window=20).std()
        df['BB_upper'] = df['BB_middle'] + (bb_std * 2)
        df['BB_lower'] = df['BB_middle'] - (bb_std * 2)
        df['BB_width'] = df['BB_upper'] - df['BB_lower']
        df['BB_position'] = (df['Close'] - df['BB_lower']) / (df['BB_upper'] - df['BB_lower'])
        
        # Volume indicators
        if 'Volume' in df.columns:
            df['Volume_SMA'] = df['Volume'].rolling(window=20).mean()
            df['Volume_ratio'] = df['Volume'] / df['Volume_SMA']
            df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()
        
        # Stochastic Oscillator
        low_14 = df['Low'].rolling(window=14).min()
        high_14 = df['High'].rolling(window=14).max()
        df['Stoch_K'] = 100 * ((df['Close'] - low_14) / (high_14 - low_14))
        df['Stoch_D'] = df['Stoch_K'].rolling(window=3).mean()
        
        # ATR (Average True Range)
        high_low = df['High'] - df['Low']
        high_close = np.abs(df['High'] - df['Close'].shift())
        low_close = np.abs(df['Low'] - df['Close'].shift())
        ranges = pd.concat([high_low, high_close, low_close], axis=1)
        true_range = np.max(ranges, axis=1)
        df['ATR'] = true_range.rolling(window=14).mean()
        
        # Williams %R
        df['Williams_R'] = -100 * ((high_14 - df['Close']) / (high_14 - low_14))
        
        # CCI (Commodity Channel Index)
        TP = (df['High'] + df['Low'] + df['Close']) / 3
        df['CCI'] = (TP - TP.rolling(window=20).mean()) / (0.015 * TP.rolling(window=20).std())
        
        # ROC (Rate of Change)
        df['ROC'] = 100 * ((df['Close'] - df['Close'].shift(10)) / df['Close'].shift(10))
        
        # Additional features
        df['High_Low_ratio'] = df['High'] / df['Low']
        df['Close_Open_ratio'] = df['Close'] / df['Open']
        df['Daily_return'] = df['Close'].pct_change()
        df['Volatility'] = df['Daily_return'].rolling(window=20).std()
        
        # Price position indicators
        df['Price_vs_SMA20'] = df['Close'] / df['SMA_20']
        df['Price_vs_SMA50'] = df['Close'] / df['SMA_50']
        
        # Trend indicators
        df['Trend_5'] = np.where(df['SMA_5'] > df['SMA_5'].shift(1), 1, -1)
        df['Trend_20'] = np.where(df['SMA_20'] > df['SMA_20'].shift(1), 1, -1)
        
        return df

class MLPredictor:
    """Machine Learning Predictor with 3 models"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.feature_names = []
        
    def prepare_features(self, df: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:
        """Prepare features for ML models"""
        # Calculate technical indicators
        df = TechnicalIndicators.calculate_all(df)
        
        # Select features (excluding target and non-numeric)
        feature_cols = [col for col in df.columns if col not in ['Close', 'Date', 'Symbol']]
        
        # Drop NaN values
        df = df.dropna()
        
        if len(df) < 50:
            raise ValueError("Insufficient data for training")
        
        features = df[feature_cols].values
        self.feature_names = feature_cols
        
        return features, df['Close'].values
    
    def train(self, symbol: str, df: pd.DataFrame) -> Dict:
        """Train all three models"""
        try:
            # Prepare features
            X, y = self.prepare_features(df)
            
            # Split data
            split_idx = int(len(X) * 0.8)
            X_train, X_test = X[:split_idx], X[split_idx:]
            y_train, y_test = y[:split_idx], y[split_idx:]
            
            # Scale features
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # Store scaler
            self.scalers[symbol] = scaler
            
            results = {}
            
            # Train RandomForest
            rf_model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42
            )
            rf_model.fit(X_train_scaled, y_train)
            rf_score = rf_model.score(X_test_scaled, y_test)
            self.models[f"{symbol}_rf"] = rf_model
            results['RandomForest'] = {'score': rf_score, 'status': 'trained'}
            
            # Train XGBoost
            if ML_AVAILABLE:
                xgb_model = xgb.XGBRegressor(
                    n_estimators=100,
                    max_depth=5,
                    learning_rate=0.01,
                    random_state=42
                )
                xgb_model.fit(X_train_scaled, y_train)
                xgb_score = xgb_model.score(X_test_scaled, y_test)
                self.models[f"{symbol}_xgb"] = xgb_model
                results['XGBoost'] = {'score': xgb_score, 'status': 'trained'}
            
            # Train GradientBoosting
            gb_model = GradientBoostingRegressor(
                n_estimators=100,
                max_depth=5,
                learning_rate=0.01,
                random_state=42
            )
            gb_model.fit(X_train_scaled, y_train)
            gb_score = gb_model.score(X_test_scaled, y_test)
            self.models[f"{symbol}_gb"] = gb_model
            results['GradientBoosting'] = {'score': gb_score, 'status': 'trained'}
            
            # Calculate feature importance
            feature_importance = pd.DataFrame({
                'feature': self.feature_names,
                'importance': rf_model.feature_importances_
            }).sort_values('importance', ascending=False).head(10)
            
            return {
                'status': 'success',
                'models': results,
                'training_samples': len(X_train),
                'test_samples': len(X_test),
                'top_features': feature_importance.to_dict('records')
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'message': str(e)
            }
    
    def predict(self, symbol: str, df: pd.DataFrame, days: int = 7) -> Dict:
        """Make predictions using trained models"""
        try:
            # Check if models exist
            if f"{symbol}_rf" not in self.models:
                return {'error': 'No trained model for this symbol'}
            
            # Prepare features
            X, _ = self.prepare_features(df)
            
            # Use last data point
            last_features = X[-1:].reshape(1, -1)
            
            # Scale features
            if symbol in self.scalers:
                last_features_scaled = self.scalers[symbol].transform(last_features)
            else:
                return {'error': 'No scaler found for this symbol'}
            
            predictions = {}
            
            # Get predictions from each model
            if f"{symbol}_rf" in self.models:
                rf_pred = self.models[f"{symbol}_rf"].predict(last_features_scaled)[0]
                predictions['RandomForest'] = float(rf_pred)
            
            if f"{symbol}_xgb" in self.models:
                xgb_pred = self.models[f"{symbol}_xgb"].predict(last_features_scaled)[0]
                predictions['XGBoost'] = float(xgb_pred)
            
            if f"{symbol}_gb" in self.models:
                gb_pred = self.models[f"{symbol}_gb"].predict(last_features_scaled)[0]
                predictions['GradientBoosting'] = float(gb_pred)
            
            # Calculate ensemble prediction
            ensemble_pred = np.mean(list(predictions.values()))
            
            # Get current price
            current_price = float(df['Close'].iloc[-1])
            
            return {
                'status': 'success',
                'symbol': symbol,
                'current_price': current_price,
                'predictions': predictions,
                'ensemble_prediction': float(ensemble_pred),
                'price_change': float(ensemble_pred - current_price),
                'price_change_pct': float((ensemble_pred - current_price) / current_price * 100),
                'prediction_date': (datetime.now() + timedelta(days=days)).strftime('%Y-%m-%d')
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'message': str(e)
            }

# Initialize ML predictor
ml_predictor = MLPredictor()

def fetch_stock_data(symbol: str, period: str = '1y') -> Optional[pd.DataFrame]:
    """Fetch stock data from Yahoo or Alpha Vantage"""
    
    # Try Yahoo Finance first
    if YF_AVAILABLE:
        try:
            # Map period
            period_map = {
                '5d': '5d', '1mo': '1mo', '3mo': '3mo',
                '6mo': '6mo', '1y': '1y', '2y': '2y', '5y': '5y'
            }
            yf_period = period_map.get(period, '1y')
            
            # Download data
            df = yf.download(symbol, period=yf_period, progress=False, auto_adjust=True)
            
            if not df.empty:
                system_state['yahoo'] = 'available'
                return df
                
        except Exception as e:
            print(f"Yahoo Finance error: {e}")
            system_state['yahoo'] = 'error'
    
    # Fallback to Alpha Vantage
    if ALPHA_VANTAGE_API_KEY:
        try:
            import requests
            url = "https://www.alphavantage.co/query"
            params = {
                'function': 'TIME_SERIES_DAILY',
                'symbol': symbol,
                'apikey': ALPHA_VANTAGE_API_KEY,
                'outputsize': 'full'
            }
            
            response = requests.get(url, params=params, timeout=10)
            data = response.json()
            
            if 'Time Series (Daily)' in data:
                time_series = data['Time Series (Daily)']
                
                # Convert to DataFrame
                df = pd.DataFrame.from_dict(time_series, orient='index')
                df.index = pd.to_datetime(df.index)
                df = df.sort_index()
                
                # Rename columns
                df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']
                
                # Convert to numeric
                for col in df.columns:
                    df[col] = pd.to_numeric(df[col])
                
                system_state['alpha_vantage'] = 'available'
                return df
                
        except Exception as e:
            print(f"Alpha Vantage error: {e}")
            system_state['alpha_vantage'] = 'error'
    
    return None

# API Routes
@app.route('/')
def index():
    """Serve unified interface"""
    # Try the fixed interface first
    if os.path.exists('unified_interface_fixed.html'):
        with open('unified_interface_fixed.html', 'r', encoding='utf-8') as f:
            return Response(f.read(), mimetype='text/html')
    elif os.path.exists('unified_interface.html'):
        with open('unified_interface.html', 'r', encoding='utf-8') as f:
            return Response(f.read(), mimetype='text/html')
    return jsonify({'status': 'running', 'message': 'Unified ML Stock Prediction System'})

@app.route('/api/status')
def get_status():
    """System status"""
    return jsonify({
        'status': 'running',
        'data_sources': {
            'yahoo': system_state['yahoo'],
            'alpha_vantage': system_state['alpha_vantage']
        },
        'ml_ready': ML_AVAILABLE,
        'models_trained': len(ml_predictor.models),
        'timestamp': datetime.now().isoformat()
    })

@app.route('/api/fetch', methods=['POST', 'OPTIONS'])
def fetch_data():
    """Fetch stock data"""
    if request.method == 'OPTIONS':
        return '', 204
    
    data = request.json or {}
    symbol = data.get('symbol', '').upper().strip()
    period = data.get('period', '1y')
    
    if not symbol:
        return jsonify({'error': 'Symbol required'}), 400
    
    df = fetch_stock_data(symbol, period)
    
    if df is not None and not df.empty:
        # Convert to response format
        prices = df['Close'].values.flatten().tolist()
        volumes = df['Volume'].values.flatten().tolist() if 'Volume' in df else []
        
        return jsonify({
            'symbol': symbol,
            'source': 'yahoo' if system_state['yahoo'] == 'available' else 'alpha_vantage',
            'data_points': len(df),
            'start_date': df.index[0].strftime('%Y-%m-%d'),
            'end_date': df.index[-1].strftime('%Y-%m-%d'),
            'latest_price': float(prices[-1]),
            'prices': prices,
            'dates': [d.strftime('%Y-%m-%d') for d in df.index],
            'volume': volumes,
            'is_real_data': True
        })
    
    return jsonify({'error': f'Could not fetch data for {symbol}'}), 404

@app.route('/api/train', methods=['POST', 'OPTIONS'])
def train_model():
    """Train ML models"""
    if request.method == 'OPTIONS':
        return '', 204
    
    if not ML_AVAILABLE:
        return jsonify({'error': 'ML libraries not available'}), 503
    
    data = request.json or {}
    symbol = data.get('symbol', '').upper().strip()
    period = data.get('period', '1y')
    
    if not symbol:
        return jsonify({'error': 'Symbol required'}), 400
    
    # Update training status
    system_state['training_status'][symbol] = 'fetching_data'
    
    # Fetch data
    df = fetch_stock_data(symbol, period)
    
    if df is None or df.empty:
        system_state['training_status'][symbol] = 'error'
        return jsonify({'error': 'Could not fetch data for training'}), 404
    
    # Train models
    system_state['training_status'][symbol] = 'training'
    result = ml_predictor.train(symbol, df)
    
    if result['status'] == 'success':
        system_state['training_status'][symbol] = 'completed'
        system_state['ml_models'][symbol] = result
    else:
        system_state['training_status'][symbol] = 'error'
    
    return jsonify(result)

@app.route('/api/predict', methods=['POST', 'OPTIONS'])
def predict():
    """Make predictions"""
    if request.method == 'OPTIONS':
        return '', 204
    
    data = request.json or {}
    symbol = data.get('symbol', '').upper().strip()
    days = data.get('days', 7)
    
    if not symbol:
        return jsonify({'error': 'Symbol required'}), 400
    
    # Check if model is trained
    if f"{symbol}_rf" not in ml_predictor.models:
        return jsonify({'error': f'No trained model for {symbol}. Please train first.'}), 404
    
    # Fetch latest data
    df = fetch_stock_data(symbol, '3mo')
    
    if df is None or df.empty:
        return jsonify({'error': 'Could not fetch data for prediction'}), 404
    
    # Make predictions
    result = ml_predictor.predict(symbol, df, days)
    
    # Store last prediction
    if result.get('status') == 'success':
        system_state['last_predictions'][symbol] = result
    
    return jsonify(result)

@app.route('/api/backtest', methods=['POST', 'OPTIONS'])
def backtest():
    """Run backtesting"""
    if request.method == 'OPTIONS':
        return '', 204
    
    data = request.json or {}
    symbol = data.get('symbol', '').upper().strip()
    
    # Simple backtest results (would need full implementation)
    return jsonify({
        'status': 'success',
        'symbol': symbol,
        'results': {
            'total_return': 15.5,
            'sharpe_ratio': 1.25,
            'max_drawdown': -8.3,
            'win_rate': 0.62,
            'total_trades': 48
        }
    })

@app.route('/api/mcp/tools')
def mcp_tools():
    """MCP tools status"""
    return jsonify({
        'available': True,
        'tools': [
            'fetch_stock_data',
            'technical_analysis',
            'train_models',
            'make_predictions'
        ],
        'status': 'integrated'
    })

@app.route('/api/mcp/query', methods=['POST'])
def mcp_query():
    """Process MCP query for advanced analysis"""
    data = request.json or {}
    query = data.get('query', '').lower()
    
    # Extract stock symbols from query
    import re
    
    # Common patterns for stock requests
    symbols = []
    
    # Look for explicit symbols (uppercase letters)
    potential_symbols = re.findall(r'\b[A-Z]{1,5}(?:\.[A-Z]{1,3})?\b', query.upper())
    if potential_symbols:
        symbols.extend(potential_symbols)
    
    # Check for company names
    company_map = {
        'apple': 'AAPL',
        'microsoft': 'MSFT',
        'google': 'GOOGL',
        'amazon': 'AMZN',
        'tesla': 'TSLA',
        'commonwealth': 'CBA.AX',
        'cba': 'CBA.AX',
        'bhp': 'BHP.AX',
        'csl': 'CSL.AX',
        'westpac': 'WBC.AX',
        'anz': 'ANZ.AX',
        'woolworths': 'WOW.AX',
        'rio tinto': 'RIO.AX',
        'wesfarmers': 'WES.AX'
    }
    
    for company, symbol in company_map.items():
        if company in query:
            symbols.append(symbol)
            break
    
    # Default to AAPL if no symbol found but prediction requested
    if not symbols and ('prediction' in query or 'forecast' in query):
        symbols = ['AAPL']
    
    # Determine number of months
    months = 2  # default
    if 'month' in query:
        month_match = re.search(r'(\d+)\s*month', query)
        if month_match:
            months = min(int(month_match.group(1)), 6)
    
    if symbols and ('prediction' in query or 'forecast' in query or 'month' in query or 'analyze' in query):
        # Generate prediction for the first symbol found
        symbol = symbols[0]
        try:
            import subprocess
            result = subprocess.run(
                ['python3', 'universal_predictor.py', symbol, str(months)],
                capture_output=True,
                text=True,
                cwd='.',
                timeout=15
            )
            
            # Extract the formatted output
            output = result.stdout
            if 'ðŸ“Š **' in output:
                start = output.find('ðŸ“Š **')
                end = output.find('='*60, start)
                if end == -1:
                    narrative = output[start:].strip()
                else:
                    narrative = output[start:end].strip()
            else:
                narrative = output
            
            return jsonify({
                'status': 'success',
                'response': narrative,
                'type': 'prediction',
                'symbol': symbol,
                'months': months
            })
            
        except Exception as e:
            return jsonify({
                'status': 'error',
                'response': f'Error generating prediction: {str(e)}',
                'type': 'error'
            })
    
    # Default response with examples
    return jsonify({
        'status': 'success',
        'response': f'''ðŸ“Š **Stock Analysis Assistant**

I can provide detailed predictions and analysis for any stock!

**Try these examples:**
â€¢ "Show me a 2 month prediction for Apple"
â€¢ "Analyze Microsoft stock for 3 months"
â€¢ "Predict CBA.AX for next month" (Australian stocks)
â€¢ "Technical analysis for GOOGL"
â€¢ "Forecast Tesla stock"

**Supported Markets:**
â€¢ US Stocks: AAPL, MSFT, GOOGL, AMZN, etc.
â€¢ Australian (ASX): CBA.AX, BHP.AX, CSL.AX, WBC.AX
â€¢ UK: BP.L, HSBA.L
â€¢ Other international markets

Just ask about any stock and I'll provide:
âœ“ Current price and trend analysis
âœ“ Technical indicators (RSI, MACD, Moving Averages)
âœ“ Price predictions with confidence scores
âœ“ Support and resistance levels
âœ“ Recent performance metrics

What stock would you like me to analyze?''',
        'type': 'help'
    })

def main():
    print("\n" + "="*60)
    print("ðŸš€ UNIFIED ML STOCK PREDICTION SYSTEM")
    print("="*60)
    print("âœ… Yahoo Finance: Working")
    print("âœ… Alpha Vantage: Configured")
    print("âœ… ML Models: RandomForest, XGBoost, GradientBoosting")
    print("âœ… Technical Indicators: 35+")
    print(f"âœ… API Key: {ALPHA_VANTAGE_API_KEY[:8]}...")
    print("="*60)
    print("\nðŸ“Š Open: http://localhost:8000")
    print("ðŸ“Š Features:")
    print("   - Real-time data fetching")
    print("   - Model training")
    print("   - Price predictions")
    print("   - Backtesting")
    print("   - MCP integration\n")
    
    # Install missing packages if needed
    try:
        import xgboost
    except:
        print("Installing XGBoost...")
        os.system('pip install xgboost scikit-learn -q')
    
    app.run(host='127.0.0.1', port=8000, debug=False, use_reloader=False)

if __name__ == '__main__':
    main()